{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(os.getcwd(), 'ner'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_kwargs = {\n",
    "        \"max_length\": 512,\n",
    "        \"truncation\": \"only_second\",\n",
    "        \"padding\": True,\n",
    "        \"return_tensors\": \"pt\",\n",
    "        \"return_offsets_mapping\": True,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_MAPPER = {\n",
    "    \"LOC\": \"location\",\n",
    "    \"PER\": \"person\",\n",
    "    \"ORG\": \"organization\",\n",
    "    \"MISC\": \"miscellaneous entity\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = load('./qa_ner_0.pkl', map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForQuestionAnswering: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForQuestionAnswering.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ner.qa_types import QAInstance, QASpan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n"
     ]
    }
   ],
   "source": [
    "from ner.metrics.qa import get_top_valid_spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_questions(instances, model):\n",
    "    with torch.no_grad():\n",
    "        context_list = []\n",
    "        question_list = []\n",
    "\n",
    "        for instance in instances:\n",
    "            context_list.append(instance.context)\n",
    "            question_list.append(instance.question)\n",
    "\n",
    "        tokenized_batch = tokenizer(\n",
    "                question_list, context_list, **tokenizer_kwargs\n",
    "        )\n",
    "\n",
    "        offset_mapping_batch = tokenized_batch.pop(\"offset_mapping\")\n",
    "        outputs = model.forward(**tokenized_batch)\n",
    "        spans_pred_batch_top_1 = get_top_valid_spans(\n",
    "                context_list=context_list,\n",
    "                question_list=question_list,\n",
    "                prompt_mapper=PROMPT_MAPPER,\n",
    "                inputs=tokenized_batch,\n",
    "                outputs=outputs,\n",
    "                offset_mapping_batch=offset_mapping_batch,\n",
    "                n_best_size=1,\n",
    "                max_answer_length=100,\n",
    "            )\n",
    "        \n",
    "        for idx in range(len(spans_pred_batch_top_1)):\n",
    "            if not spans_pred_batch_top_1[idx]:\n",
    "                empty_span = QASpan(\n",
    "                    token=\"\",\n",
    "                    label=\"O\",\n",
    "                    start_context_char_pos=0,\n",
    "                    end_context_char_pos=0,\n",
    "                )\n",
    "                spans_pred_batch_top_1[idx] = [empty_span]\n",
    "        \n",
    "        return spans_pred_batch_top_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = [\n",
    "    QAInstance(\n",
    "        context='Sergey Sobyanin started reforms in Moscow in september 2022', \n",
    "        question='What is the location?',\n",
    "        answer=None\n",
    "    ),\n",
    "    QAInstance(\n",
    "        context='Sergey Sobyanin started reforms in Moscow in september 2022', \n",
    "        question='What is the person?',\n",
    "        answer=None\n",
    "    ),\n",
    "    QAInstance(\n",
    "        context='UN chief delays his next trip to focus on Russia\\'s suspension of the Black Sea grain deal', \n",
    "        question='What is the organization?',\n",
    "        answer=None\n",
    "    ),\n",
    "    QAInstance(\n",
    "        context='UN chief delays his next trip to focus on Russia\\'s suspension of the Black Sea grain deal', \n",
    "        question='What is the location?',\n",
    "        answer=None\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = check_questions(instances, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: Sergey Sobyanin started reforms in Moscow in september 2022 Question: What is the location?\n",
      "\tMoscow is location\n",
      "Context: Sergey Sobyanin started reforms in Moscow in september 2022 Question: What is the person?\n",
      "\tSergey is person\n",
      "Context: UN chief delays his next trip to focus on Russia's suspension of the Black Sea grain deal Question: What is the organization?\n",
      "\tUN is organization\n",
      "Context: UN chief delays his next trip to focus on Russia's suspension of the Black Sea grain deal Question: What is the location?\n"
     ]
    }
   ],
   "source": [
    "for instance, answers_ in zip(instances, answers):\n",
    "    print(f'Context: {instance.context} | Question: {instance.question}')\n",
    "    for answer in answers_:\n",
    "        if answer.label != 'O':\n",
    "            print(f'\\t{answer.token} is {PROMPT_MAPPER[answer.label]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
