{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тестовое задание \n",
    "\n",
    "   Ваша задача написать пайплайн для тренировки модели глубоко обучения (любую – **embeddings + LSTM, Bert** …) с использованием следующих инструментов: pytorch, sklearn, matplotlib – для решения задачи **NER** (извлечения сущностей).\n",
    "\n",
    "   В качестве данных используется датасет **Conll2003** с четырьмя классами **Per, Org, Loc, Misc** в формате **Conll**.\n",
    "\n",
    "   В тетрадке ниже заданы основные классы и функции для построения требуемого пайплайн, какие-то уже имплементированы, какие-то – нет. Их требуется доработать. Тем не менее если данный набор абстракций вам не подходит Вы можете написать свой пайплайн «с нуля», однако обоснованность у этих действий должна быть.\n",
    "\n",
    "**Что оценивается в первую очередь:**\n",
    "- Выбранная архитектура для решения задачи (генеративная/экстрактивная)\n",
    "- Выбранные предобученные веса \n",
    "- Полученные метрики\n",
    "- Анализ ошибок модели\n",
    "\n",
    "**Затем:**\n",
    "- Глубина разведочного анализа (EDA)\n",
    "- Испольуземые инстурменты для сравнения экспериментов\n",
    "- Какая схема теггирования используется (**BIO, IO** или другие)\n",
    "- Каким образом производится расчет метрик (потокенный отчет, отчет по точному совпадению спанов сущностей)\n",
    "\n",
    "**С меньшим приоритетом:** \n",
    "- Скорость предобработки и постобработки данных \n",
    "- Стиль кода"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Варианты решения\n",
    "\n",
    "Для кодировки таргета я по-умолчанию использую IO кодировку, но возможность использовать BIO кодировку также присутствует. В случае с сущностями из датасета Conll2003 нет особенной разницы в использовании BIO, IO, BIOE, BIOES разметки, так как большая часть сущностей представляет собой 1-2 токена.\n",
    "\n",
    "### NER как задача разметки последовательности\n",
    "\n",
    "Самый очевидный подход к решению задачи извлечения сущностей. Для решения я выбрал две архитектуры:\n",
    "* CNN-BiLSTM-Softmax и GLOVE как бэйзлайн на чистом PyTorch (Ноутбук: CNN-biLSTM-Softmax.ipynb, Macro F1 Score: by tokens 0.87, by spans 0.83). Я использовал гиперпараметры из статьи https://arxiv.org/pdf/1511.08308v5.pdf; \n",
    "* BERT-Softmax (Ноутбук: BERT-HF.ipynb, Macro F1 Score: by tokens 0.91, by spans 0.91). Для реализации этого варианта я использовал фреймворк HuggingFace и предобученную модель 'bert-base-cased', файнтюнил модель на Google Colab;\n",
    "\n",
    "\n",
    "### NER как Question Answering\n",
    "\n",
    "Протестировать работу модели можно в ноутбуке: Test QANer.ipynb.\n",
    "\n",
    "Так как для исходной задачи подразумевается отсутствие какой-либо разметки и есть только данные типа \"текст - что нужно извлечь\" я решил попробовать поставить задачу иным способом. \n",
    "\n",
    "Самым очевидным вариантом было использовать подход \"NER как NMT задача\" (Template-Based Named Entity Recognition Using BART, 2021: https://arxiv.org/abs/2106.01760 ), но репозиторий из статьи (https://github.com/Nealcly/templateNER) не содержит в себе предобученную модель. И я решил отказаться от этого подхода, так как обучать с нуля модель на своем ноутбуке достаточно трудоемко.\n",
    "\n",
    "Вместо этого я решил попробовать подход из статьи QaNER: Prompting Question Answering Models for Few-shot Named Entity Recognition, 2022: https://arxiv.org/abs/2203.01543 и для этого адаптировал код из репозитория https://github.com/dayyass/QaNER/ под датасет Conll2003 и пайплайн из исходного задания. Для решения задачи QA я использую предобученную модель из HuggingFace BERTForQuestionAbswering('bert-base-uncased')\n",
    "\n",
    "Финальный ноутбук: QANer.ipynb, Macro F1 Score: by tokens 0.90."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
